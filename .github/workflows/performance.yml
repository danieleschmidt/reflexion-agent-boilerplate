name: Performance Regression

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  benchmark:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for comparison

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: Run benchmarks
      run: |
        python benchmarks/run_all.py --output benchmark-results.json

    - name: Store benchmark results
      uses: benchmark-action/github-action-benchmark@v1
      with:
        tool: 'pytest'
        output-file-path: benchmark-results.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        comment-on-alert: true
        alert-threshold: '105%'  # Alert if 5% slower
        fail-on-alert: true

    - name: Performance regression check
      run: |
        # Custom performance regression detection
        python -c "
        import json
        import sys
        
        try:
            with open('benchmark-results.json', 'r') as f:
                results = json.load(f)
            
            # Simple regression check - customize based on your benchmark format
            for benchmark in results.get('benchmarks', []):
                if benchmark.get('regression_threshold', 1.0) > 1.05:
                    print(f'Performance regression detected in {benchmark[\"name\"]}')
                    sys.exit(1)
                    
            print('No performance regressions detected')
        except Exception as e:
            print(f'Error checking performance: {e}')
            # Don't fail on error during performance check
        "

    - name: Upload benchmark artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: benchmark-results
        path: benchmark-results.json