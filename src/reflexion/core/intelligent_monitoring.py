"""
Intelligent monitoring system with predictive analytics and anomaly detection.
"""

import asyncio
import time
import json
import math
from typing import Dict, List, Any, Optional, Callable, Union, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict, deque
import threading
import logging
from statistics import mean, stdev

from .logging_config import logger


class MetricType(Enum):
    """Types of metrics tracked by the monitoring system."""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    TIMER = "timer"
    RATE = "rate"


class AlertSeverity(Enum):
    """Alert severity levels."""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class AnomalyType(Enum):
    """Types of anomalies detected."""
    SPIKE = "spike"
    DROP = "drop"
    TREND_CHANGE = "trend_change"
    OUTLIER = "outlier"
    PATTERN_BREAK = "pattern_break"


@dataclass
class Metric:
    """Individual metric data point."""
    name: str
    value: Union[int, float]
    timestamp: datetime
    labels: Dict[str, str] = field(default_factory=dict)
    metric_type: MetricType = MetricType.GAUGE
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "value": self.value,
            "timestamp": self.timestamp.isoformat(),
            "labels": self.labels,
            "type": self.metric_type.value
        }


@dataclass
class Alert:
    """Alert generated by monitoring system."""
    id: str
    message: str
    severity: AlertSeverity
    metric_name: str
    current_value: Union[int, float]
    threshold: Union[int, float]
    timestamp: datetime
    resolved: bool = False
    resolution_timestamp: Optional[datetime] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "message": self.message,
            "severity": self.severity.value,
            "metric_name": self.metric_name,
            "current_value": self.current_value,
            "threshold": self.threshold,
            "timestamp": self.timestamp.isoformat(),
            "resolved": self.resolved,
            "resolution_timestamp": self.resolution_timestamp.isoformat() if self.resolution_timestamp else None
        }


@dataclass
class Anomaly:
    """Detected anomaly in metrics."""
    id: str
    anomaly_type: AnomalyType
    metric_name: str
    detected_value: Union[int, float]
    expected_range: Tuple[float, float]
    confidence: float
    timestamp: datetime
    context: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "type": self.anomaly_type.value,
            "metric_name": self.metric_name,
            "detected_value": self.detected_value,
            "expected_range": self.expected_range,
            "confidence": self.confidence,
            "timestamp": self.timestamp.isoformat(),
            "context": self.context
        }


class TimeSeriesAnalyzer:
    """Advanced time series analysis for anomaly detection."""
    
    def __init__(self, window_size: int = 50):
        self.window_size = window_size
        self.metric_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=window_size))
        self.trend_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=20))
        
    def add_data_point(self, metric_name: str, value: float, timestamp: datetime):
        """Add data point for analysis."""
        self.metric_history[metric_name].append((timestamp, value))
    
    def detect_anomalies(self, metric_name: str, current_value: float) -> List[Anomaly]:
        """Detect anomalies in metric data."""
        
        if len(self.metric_history[metric_name]) < 10:
            return []  # Need sufficient data for analysis
        
        anomalies = []
        history = list(self.metric_history[metric_name])
        values = [v for _, v in history]
        
        # Statistical anomaly detection
        statistical_anomaly = self._detect_statistical_anomaly(metric_name, current_value, values)
        if statistical_anomaly:
            anomalies.append(statistical_anomaly)
        
        # Trend anomaly detection
        trend_anomaly = self._detect_trend_anomaly(metric_name, current_value, values)
        if trend_anomaly:
            anomalies.append(trend_anomaly)
        
        # Pattern break detection
        pattern_anomaly = self._detect_pattern_break(metric_name, current_value, history)
        if pattern_anomaly:
            anomalies.append(pattern_anomaly)
        
        return anomalies
    
    def _detect_statistical_anomaly(self, metric_name: str, current_value: float, values: List[float]) -> Optional[Anomaly]:
        """Detect statistical outliers using z-score."""
        
        if len(values) < 10:
            return None
        
        mean_val = mean(values)
        std_val = stdev(values) if len(values) > 1 else 0
        
        if std_val == 0:
            return None
        
        z_score = abs((current_value - mean_val) / std_val)
        
        if z_score > 3.0:  # 3-sigma rule
            anomaly_type = AnomalyType.SPIKE if current_value > mean_val else AnomalyType.DROP
            
            return Anomaly(
                id=f"stat_{metric_name}_{int(time.time())}",
                anomaly_type=anomaly_type,
                metric_name=metric_name,
                detected_value=current_value,
                expected_range=(mean_val - 2*std_val, mean_val + 2*std_val),
                confidence=min(1.0, z_score / 5.0),
                timestamp=datetime.now(),
                context={"z_score": z_score, "mean": mean_val, "std": std_val}
            )
        
        return None
    
    def _detect_trend_anomaly(self, metric_name: str, current_value: float, values: List[float]) -> Optional[Anomaly]:
        """Detect sudden trend changes."""
        
        if len(values) < 20:
            return None
        
        # Calculate recent trend (last 10 values)
        recent_values = values[-10:]
        older_values = values[-20:-10]
        
        recent_trend = self._calculate_trend(recent_values)
        older_trend = self._calculate_trend(older_values)
        
        # Detect significant trend change
        trend_change = abs(recent_trend - older_trend)
        
        if trend_change > 0.5:  # Significant trend change threshold
            self.trend_history[metric_name].append(recent_trend)
            
            return Anomaly(
                id=f"trend_{metric_name}_{int(time.time())}",
                anomaly_type=AnomalyType.TREND_CHANGE,
                metric_name=metric_name,
                detected_value=current_value,
                expected_range=(min(values), max(values)),
                confidence=min(1.0, trend_change),
                timestamp=datetime.now(),
                context={
                    "recent_trend": recent_trend,
                    "older_trend": older_trend,
                    "trend_change": trend_change
                }
            )
        
        return None
    
    def _detect_pattern_break(self, metric_name: str, current_value: float, history: List[Tuple[datetime, float]]) -> Optional[Anomaly]:
        """Detect breaks in temporal patterns."""
        
        if len(history) < 30:
            return None
        
        # Analyze cyclical patterns (e.g., daily, weekly)
        hourly_patterns = self._analyze_hourly_pattern(history)
        
        current_hour = datetime.now().hour
        expected_range = hourly_patterns.get(current_hour)
        
        if expected_range:
            expected_min, expected_max = expected_range
            
            if current_value < expected_min * 0.5 or current_value > expected_max * 2.0:
                return Anomaly(
                    id=f"pattern_{metric_name}_{int(time.time())}",
                    anomaly_type=AnomalyType.PATTERN_BREAK,
                    metric_name=metric_name,
                    detected_value=current_value,
                    expected_range=expected_range,
                    confidence=0.7,
                    timestamp=datetime.now(),
                    context={"hour": current_hour, "hourly_patterns": hourly_patterns}
                )
        
        return None
    
    def _calculate_trend(self, values: List[float]) -> float:
        """Calculate trend slope using linear regression."""
        
        if len(values) < 2:
            return 0.0
        
        n = len(values)
        x_values = list(range(n))
        
        # Simple linear regression
        sum_x = sum(x_values)
        sum_y = sum(values)
        sum_xy = sum(x * y for x, y in zip(x_values, values))
        sum_x2 = sum(x * x for x in x_values)
        
        denominator = n * sum_x2 - sum_x * sum_x
        if denominator == 0:
            return 0.0
        
        slope = (n * sum_xy - sum_x * sum_y) / denominator
        return slope
    
    def _analyze_hourly_pattern(self, history: List[Tuple[datetime, float]]) -> Dict[int, Tuple[float, float]]:
        """Analyze hourly patterns in data."""
        
        hourly_data = defaultdict(list)
        
        for timestamp, value in history:
            hour = timestamp.hour
            hourly_data[hour].append(value)
        
        hourly_patterns = {}
        for hour, values in hourly_data.items():
            if len(values) >= 3:
                mean_val = mean(values)
                std_val = stdev(values) if len(values) > 1 else 0
                hourly_patterns[hour] = (mean_val - std_val, mean_val + std_val)
        
        return hourly_patterns


class PredictiveAnalytics:
    """Predictive analytics for proactive monitoring."""
    
    def __init__(self):
        self.prediction_models: Dict[str, Any] = {}
        self.prediction_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=100))
        
    def predict_metric_value(self, metric_name: str, values: List[float], horizon: int = 5) -> List[float]:
        """Predict future metric values."""
        
        if len(values) < 10:
            return [values[-1]] * horizon  # Simple fallback
        
        # Simple moving average prediction
        recent_values = values[-5:]
        trend = sum(recent_values[i] - recent_values[i-1] for i in range(1, len(recent_values))) / (len(recent_values) - 1)
        
        predictions = []
        last_value = values[-1]
        
        for i in range(horizon):
            predicted_value = last_value + trend * (i + 1)
            predictions.append(predicted_value)
        
        return predictions
    
    def predict_anomaly_likelihood(self, metric_name: str, values: List[float]) -> float:
        """Predict likelihood of anomaly in near future."""
        
        if len(values) < 20:
            return 0.0
        
        # Calculate recent volatility
        recent_values = values[-10:]
        volatility = stdev(recent_values) if len(recent_values) > 1 else 0
        
        # Calculate trend acceleration
        trend_recent = self._calculate_trend(values[-5:])
        trend_older = self._calculate_trend(values[-10:-5])
        trend_acceleration = abs(trend_recent - trend_older)
        
        # Combine factors for anomaly likelihood
        volatility_factor = min(1.0, volatility / (mean(values) + 0.001))
        acceleration_factor = min(1.0, trend_acceleration * 10)
        
        anomaly_likelihood = (volatility_factor + acceleration_factor) / 2
        return min(1.0, anomaly_likelihood)
    
    def _calculate_trend(self, values: List[float]) -> float:
        """Calculate trend slope."""
        if len(values) < 2:
            return 0.0
        
        n = len(values)
        x_values = list(range(n))
        
        sum_x = sum(x_values)
        sum_y = sum(values)
        sum_xy = sum(x * y for x, y in zip(x_values, values))
        sum_x2 = sum(x * x for x in x_values)
        
        denominator = n * sum_x2 - sum_x * sum_x
        if denominator == 0:
            return 0.0
        
        slope = (n * sum_xy - sum_x * sum_y) / denominator
        return slope


class AlertManager:
    """Intelligent alert management with suppression and correlation."""
    
    def __init__(self):
        self.active_alerts: Dict[str, Alert] = {}
        self.alert_history = deque(maxlen=1000)
        self.suppression_rules: Dict[str, Dict] = {}
        self.correlation_rules: Dict[str, Dict] = {}
        
    def create_alert(
        self,
        metric_name: str,
        message: str,
        severity: AlertSeverity,
        current_value: Union[int, float],
        threshold: Union[int, float]
    ) -> Alert:
        """Create new alert with intelligent suppression."""
        
        alert_id = f"{metric_name}_{severity.value}_{int(time.time())}"
        
        # Check suppression rules
        if self._is_suppressed(metric_name, severity):
            logger.info(f"Alert suppressed for {metric_name}")
            return None
        
        alert = Alert(
            id=alert_id,
            message=message,
            severity=severity,
            metric_name=metric_name,
            current_value=current_value,
            threshold=threshold,
            timestamp=datetime.now()
        )
        
        self.active_alerts[alert_id] = alert
        self.alert_history.append(alert)
        
        # Check for correlations
        correlated_alerts = self._find_correlations(alert)
        if correlated_alerts:
            alert.message += f" (Correlated with: {', '.join(correlated_alerts)})"
        
        logger.warning(f"Alert created: {alert.message}")
        return alert
    
    def resolve_alert(self, alert_id: str):
        """Resolve an active alert."""
        
        if alert_id in self.active_alerts:
            alert = self.active_alerts[alert_id]
            alert.resolved = True
            alert.resolution_timestamp = datetime.now()
            del self.active_alerts[alert_id]
            logger.info(f"Alert resolved: {alert.message}")
    
    def _is_suppressed(self, metric_name: str, severity: AlertSeverity) -> bool:
        """Check if alert should be suppressed."""
        
        # Time-based suppression
        recent_alerts = [a for a in self.alert_history 
                        if a.metric_name == metric_name 
                        and a.severity == severity
                        and (datetime.now() - a.timestamp).total_seconds() < 300]  # 5 minutes
        
        if len(recent_alerts) > 5:  # Too many similar alerts
            return True
        
        return False
    
    def _find_correlations(self, alert: Alert) -> List[str]:
        """Find correlated alerts."""
        
        correlations = []
        
        # Time-based correlation (alerts within 1 minute)
        recent_window = datetime.now() - timedelta(minutes=1)
        
        for active_alert in self.active_alerts.values():
            if (active_alert.timestamp > recent_window and 
                active_alert.id != alert.id and
                active_alert.severity in [AlertSeverity.ERROR, AlertSeverity.CRITICAL]):
                correlations.append(active_alert.metric_name)
        
        return correlations
    
    def get_alert_summary(self) -> Dict[str, Any]:
        """Get comprehensive alert summary."""
        
        active_count = len(self.active_alerts)
        severity_counts = defaultdict(int)
        
        for alert in self.active_alerts.values():
            severity_counts[alert.severity.value] += 1
        
        recent_resolved = len([a for a in self.alert_history 
                             if a.resolved and 
                             (datetime.now() - a.timestamp).total_seconds() < 3600])  # Last hour
        
        return {
            "active_alerts": active_count,
            "severity_breakdown": dict(severity_counts),
            "recent_resolved": recent_resolved,
            "total_alerts_today": len([a for a in self.alert_history 
                                     if (datetime.now() - a.timestamp).days == 0]),
            "most_frequent_metrics": self._get_frequent_alert_metrics()
        }
    
    def _get_frequent_alert_metrics(self) -> List[Tuple[str, int]]:
        """Get most frequently alerted metrics."""
        
        metric_counts = defaultdict(int)
        for alert in self.alert_history:
            metric_counts[alert.metric_name] += 1
        
        return sorted(metric_counts.items(), key=lambda x: x[1], reverse=True)[:5]


class IntelligentMonitoringSystem:
    """
    Comprehensive intelligent monitoring system with:
    - Real-time metrics collection
    - Anomaly detection with ML
    - Predictive analytics
    - Intelligent alerting
    - Performance optimization recommendations
    """
    
    def __init__(self):
        self.metrics_store: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        self.time_series_analyzer = TimeSeriesAnalyzer()
        self.predictive_analytics = PredictiveAnalytics()
        self.alert_manager = AlertManager()
        
        self.metric_metadata: Dict[str, Dict] = {}
        self.thresholds: Dict[str, Dict] = {}
        self.collection_enabled = True
        
        # Background processing
        self.processing_thread = None
        self.shutdown_event = threading.Event()
        
        self.logger = logging.getLogger(__name__)
        
        # Start background processing
        self._start_background_processing()
    
    def record_metric(
        self,
        name: str,
        value: Union[int, float],
        metric_type: MetricType = MetricType.GAUGE,
        labels: Optional[Dict[str, str]] = None
    ):
        """Record a metric value."""
        
        if not self.collection_enabled:
            return
        
        timestamp = datetime.now()
        metric = Metric(
            name=name,
            value=value,
            timestamp=timestamp,
            labels=labels or {},
            metric_type=metric_type
        )
        
        self.metrics_store[name].append(metric)
        self.time_series_analyzer.add_data_point(name, float(value), timestamp)
        
        # Check thresholds and generate alerts
        self._check_thresholds(metric)
        
        # Anomaly detection
        anomalies = self.time_series_analyzer.detect_anomalies(name, float(value))
        for anomaly in anomalies:
            self._handle_anomaly(anomaly)
    
    def set_threshold(
        self,
        metric_name: str,
        threshold_type: str,  # "upper", "lower", "rate"
        value: Union[int, float],
        severity: AlertSeverity = AlertSeverity.WARNING
    ):
        """Set alert threshold for a metric."""
        
        if metric_name not in self.thresholds:
            self.thresholds[metric_name] = {}
        
        self.thresholds[metric_name][threshold_type] = {
            "value": value,
            "severity": severity
        }
        
        self.logger.info(f"Threshold set for {metric_name}: {threshold_type} = {value}")
    
    def _check_thresholds(self, metric: Metric):
        """Check if metric violates thresholds."""
        
        if metric.name not in self.thresholds:
            return
        
        thresholds = self.thresholds[metric.name]
        
        for threshold_type, config in thresholds.items():
            threshold_value = config["value"]
            severity = config["severity"]
            
            violated = False
            message = ""
            
            if threshold_type == "upper" and metric.value > threshold_value:
                violated = True
                message = f"{metric.name} exceeded upper threshold: {metric.value} > {threshold_value}"
            
            elif threshold_type == "lower" and metric.value < threshold_value:
                violated = True
                message = f"{metric.name} below lower threshold: {metric.value} < {threshold_value}"
            
            elif threshold_type == "rate":
                # Rate threshold - check change rate
                if len(self.metrics_store[metric.name]) >= 2:
                    previous_metric = self.metrics_store[metric.name][-2]
                    time_diff = (metric.timestamp - previous_metric.timestamp).total_seconds()
                    if time_diff > 0:
                        rate = (metric.value - previous_metric.value) / time_diff
                        if abs(rate) > threshold_value:
                            violated = True
                            message = f"{metric.name} rate of change exceeded threshold: {rate:.2f}/s > {threshold_value}/s"
            
            if violated:
                self.alert_manager.create_alert(
                    metric_name=metric.name,
                    message=message,
                    severity=severity,
                    current_value=metric.value,
                    threshold=threshold_value
                )
    
    def _handle_anomaly(self, anomaly: Anomaly):
        """Handle detected anomaly."""
        
        severity = AlertSeverity.WARNING
        if anomaly.confidence > 0.8:
            severity = AlertSeverity.ERROR
        
        message = (f"Anomaly detected in {anomaly.metric_name}: "
                  f"{anomaly.anomaly_type.value} - value {anomaly.detected_value} "
                  f"outside expected range {anomaly.expected_range}")
        
        self.alert_manager.create_alert(
            metric_name=anomaly.metric_name,
            message=message,
            severity=severity,
            current_value=anomaly.detected_value,
            threshold=anomaly.expected_range[1]
        )
    
    def get_metric_summary(self, metric_name: str) -> Dict[str, Any]:
        """Get comprehensive summary for a metric."""
        
        if metric_name not in self.metrics_store:
            return {"error": f"Metric {metric_name} not found"}
        
        metrics = list(self.metrics_store[metric_name])
        values = [m.value for m in metrics]
        
        if not values:
            return {"error": f"No data for metric {metric_name}"}
        
        # Basic statistics
        current_value = values[-1]
        avg_value = mean(values)
        min_value = min(values)
        max_value = max(values)
        std_value = stdev(values) if len(values) > 1 else 0
        
        # Predictions
        predictions = self.predictive_analytics.predict_metric_value(metric_name, values)
        anomaly_likelihood = self.predictive_analytics.predict_anomaly_likelihood(metric_name, values)
        
        # Recent anomalies
        recent_anomalies = self.time_series_analyzer.detect_anomalies(metric_name, current_value)
        
        return {
            "current_value": current_value,
            "statistics": {
                "average": avg_value,
                "minimum": min_value,
                "maximum": max_value,
                "standard_deviation": std_value,
                "data_points": len(values)
            },
            "predictions": {
                "next_5_values": predictions,
                "anomaly_likelihood": anomaly_likelihood
            },
            "recent_anomalies": [a.to_dict() for a in recent_anomalies],
            "thresholds": self.thresholds.get(metric_name, {}),
            "last_updated": metrics[-1].timestamp.isoformat() if metrics else None
        }
    
    def get_system_health(self) -> Dict[str, Any]:
        """Get overall system health assessment."""
        
        total_metrics = len(self.metrics_store)
        active_alerts = len(self.alert_manager.active_alerts)
        
        # Calculate health score
        health_factors = []
        
        # Alert factor (fewer alerts = better health)
        alert_factor = max(0, 1 - (active_alerts / max(1, total_metrics * 0.1)))
        health_factors.append(alert_factor)
        
        # Anomaly factor
        total_anomalies = 0
        for metric_name in list(self.metrics_store.keys())[:10]:  # Sample 10 metrics
            values = [m.value for m in self.metrics_store[metric_name]]
            if values:
                anomalies = self.time_series_analyzer.detect_anomalies(metric_name, values[-1])
                total_anomalies += len(anomalies)
        
        anomaly_factor = max(0, 1 - (total_anomalies / max(1, 10 * 0.2)))
        health_factors.append(anomaly_factor)
        
        # Prediction factor
        total_anomaly_likelihood = 0
        prediction_count = 0
        for metric_name in list(self.metrics_store.keys())[:5]:  # Sample 5 metrics
            values = [m.value for m in self.metrics_store[metric_name]]
            if len(values) >= 20:
                likelihood = self.predictive_analytics.predict_anomaly_likelihood(metric_name, values)
                total_anomaly_likelihood += likelihood
                prediction_count += 1
        
        if prediction_count > 0:
            prediction_factor = 1 - (total_anomaly_likelihood / prediction_count)
            health_factors.append(prediction_factor)
        
        overall_health = mean(health_factors) if health_factors else 0.5
        
        # Health status
        if overall_health > 0.8:
            health_status = "excellent"
        elif overall_health > 0.6:
            health_status = "good"
        elif overall_health > 0.4:
            health_status = "fair"
        elif overall_health > 0.2:
            health_status = "poor"
        else:
            health_status = "critical"
        
        return {
            "overall_health_score": overall_health,
            "health_status": health_status,
            "metrics_tracked": total_metrics,
            "active_alerts": active_alerts,
            "alert_summary": self.alert_manager.get_alert_summary(),
            "health_factors": {
                "alert_factor": alert_factor,
                "anomaly_factor": anomaly_factor,
                "prediction_factor": health_factors[2] if len(health_factors) > 2 else 0.5
            },
            "recommendations": self._get_health_recommendations(overall_health, active_alerts)
        }
    
    def _get_health_recommendations(self, health_score: float, active_alerts: int) -> List[str]:
        """Get health improvement recommendations."""
        
        recommendations = []
        
        if health_score < 0.5:
            recommendations.append("System health is poor - immediate attention required")
            recommendations.append("Review and resolve active alerts")
            recommendations.append("Check for anomalous metric patterns")
        
        if active_alerts > 10:
            recommendations.append("High number of active alerts - prioritize resolution")
            recommendations.append("Consider adjusting alert thresholds to reduce noise")
        
        if health_score < 0.7:
            recommendations.append("Monitor system performance closely")
            recommendations.append("Consider scaling resources if needed")
        
        if not recommendations:
            recommendations.append("System health is good - continue monitoring")
        
        return recommendations
    
    def _start_background_processing(self):
        """Start background processing thread."""
        
        def process_loop():
            while not self.shutdown_event.is_set():
                try:
                    # Periodic cleanup and optimization
                    self._cleanup_old_data()
                    self._optimize_thresholds()
                    
                    time.sleep(60)  # Run every minute
                except Exception as e:
                    self.logger.error(f"Background processing error: {e}")
        
        self.processing_thread = threading.Thread(target=process_loop, daemon=True)
        self.processing_thread.start()
    
    def _cleanup_old_data(self):
        """Clean up old data to prevent memory issues."""
        
        # Remove metrics older than 24 hours from memory
        cutoff_time = datetime.now() - timedelta(hours=24)
        
        for metric_name in list(self.metrics_store.keys()):
            metrics = self.metrics_store[metric_name]
            # Keep only recent metrics
            recent_metrics = deque([m for m in metrics if m.timestamp > cutoff_time], maxlen=1000)
            self.metrics_store[metric_name] = recent_metrics
    
    def _optimize_thresholds(self):
        """Automatically optimize thresholds based on historical data."""
        
        for metric_name, metrics in self.metrics_store.items():
            if len(metrics) < 100:  # Need sufficient data
                continue
            
            values = [m.value for m in metrics]
            
            # Calculate adaptive thresholds
            avg_value = mean(values)
            std_value = stdev(values) if len(values) > 1 else 0
            
            # Set upper threshold at 2 standard deviations
            upper_threshold = avg_value + 2 * std_value
            
            # Update threshold if none exists
            if (metric_name not in self.thresholds or 
                "upper" not in self.thresholds[metric_name]):
                self.set_threshold(metric_name, "upper", upper_threshold, AlertSeverity.WARNING)
    
    def stop(self):
        """Stop the monitoring system."""
        
        self.collection_enabled = False
        self.shutdown_event.set()
        
        if self.processing_thread:
            self.processing_thread.join(timeout=5)


# Global monitoring instance
intelligent_monitor = IntelligentMonitoringSystem()